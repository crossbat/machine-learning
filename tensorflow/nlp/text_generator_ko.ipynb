{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "import numpy as np\r\n",
    "import os\r\n",
    "from pdfminer.high_level import extract_text\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
    "from tensorflow.keras.utils import get_file, to_categorical\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Dense, Embedding, SimpleRNN, LSTM\r\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "data1 = 'C:/Users/Windows10/Downloads/인공 지능에서 인공 감정으로.pdf'\r\n",
    "data2 = 'C:/Users/Windows10/Downloads/RCMS에 활용하기 위한 인공지능 기반 챗봇 시스템.pdf'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "text1 = extract_text(data1)\r\n",
    "text2 = extract_text(data2)\r\n",
    "\r\n",
    "print(text1[:250])\r\n",
    "print('-'*20)\r\n",
    "print(text2[:250])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "인공 지능에서 인공 감정으로\n",
      "감정을 가진 기계는 실현가능한가?\n",
      "Artificial intelligence and artificial emotions - Is an emotion robot realizable? -\n",
      "\n",
      "저자\n",
      "\n",
      "(Authors)\n",
      "\n",
      "출처\n",
      "\n",
      "(Source)\n",
      "\n",
      "발행처\n",
      "\n",
      "(Publisher)\n",
      "\n",
      "URL\n",
      "\n",
      "APA Style\n",
      "\n",
      "천현득\n",
      " Hyundeuk Cheon\n",
      "\n",
      "철학 131, 2017.5, 217-243(27 pages)\n",
      "Korean Journ\n",
      "--------------------\n",
      "RCMS에 활용하기 위한 인공지능 기반 챗봇 시스템\n",
      "Artificial intelligence-based chatbot system for use in RCMS\n",
      "\n",
      "김용국, 김수진, 정회경\n",
      "Yongkuk Kim, Sujin Kim, Hoekyung Jung\n",
      "\n",
      "저자\n",
      "\n",
      "(Authors)\n",
      "\n",
      "출처\n",
      "\n",
      "(Source)\n",
      "\n",
      "발행처\n",
      "\n",
      "(Publisher)\n",
      "\n",
      "URL\n",
      "\n",
      "APA Style\n",
      "\n",
      "한국정보통신학회논문지 25(7), 2021.7, 877-883 (7 pages\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "text1 = text1[1500:]\r\n",
    "text2 = text2[1500:]\r\n",
    "\r\n",
    "text = text1 + text2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "vocab = sorted(set(text))\r\n",
    "\r\n",
    "vocab_size = len(vocab)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "char2idx = {u : i for i, u in enumerate(vocab)}\r\n",
    "idx2char = np.array(vocab)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "text_as_int = [char2idx[c] for c in text]\r\n",
    "print(text_as_int[:5])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[622, 722, 2, 571, 16]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "seq_len = 100\r\n",
    "\r\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "sequences = char_dataset.batch(seq_len + 1, drop_remainder= True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "def split_input_target(chunk):\r\n",
    "    input_text = chunk[:-1]\r\n",
    "    target_text = chunk[1:]\r\n",
    "\r\n",
    "    return input_text, target_text\r\n",
    "\r\n",
    "dataset = sequences.map(split_input_target)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "for input_example, target_example in dataset.take(1):\r\n",
    "    print('input_data : {}'.format(repr(''.join(idx2char[input_example.numpy()]))))\r\n",
    "    print('target_data : {}'.format(repr(''.join(idx2char[target_example.numpy()]))))\r\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "input_data : '철학 제131집 2017년 5월CHEOLHAK, Korean Philosophical AssociationVol.131, May 2017, 217-243http://dx.doi.o'\n",
      "target_data : '학 제131집 2017년 5월CHEOLHAK, Korean Philosophical AssociationVol.131, May 2017, 217-243http://dx.doi.or'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "batch_size = 64\r\n",
    "buffer_size = 10000\r\n",
    "\r\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder= True)\r\n",
    "\r\n",
    "print(dataset)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "embedding_dim = 256\r\n",
    "\r\n",
    "rnn_units = 1024"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\r\n",
    "    model = Sequential([\r\n",
    "        Embedding(vocab_size, embedding_dim, batch_input_shape = [batch_size, None]),\r\n",
    "        LSTM(rnn_units, stateful= True, return_sequences= True, recurrent_initializer= 'glorot_uniform'),\r\n",
    "        Dense(vocab_size)\r\n",
    "    ])\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "model = build_model(vocab_size= vocab_size, embedding_dim= embedding_dim, rnn_units= rnn_units, batch_size = batch_size)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\r\n",
    "    example_batch_predictions = model(input_example_batch)\r\n",
    "    print(example_batch_predictions.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(64, 100, 774)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (64, None, 256)           198144    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (64, None, 774)           793350    \n",
      "=================================================================\n",
      "Total params: 6,238,470\n",
      "Trainable params: 6,238,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\r\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis = -1).numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "sampled_indices"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([102, 706, 108, 345, 453, 704, 648, 521, 525, 604, 503, 708, 170,\n",
       "       734, 646, 489,  25, 772, 273, 456, 294, 763,  83, 625, 431, 644,\n",
       "       686, 281, 442, 360, 334, 297, 410, 165, 744, 196, 527, 124, 709,\n",
       "       566, 262, 575, 232, 346, 664, 138, 433, 618, 127,  25,  36, 420,\n",
       "       742, 465, 652, 720, 337, 415, 742, 705, 135, 412, 493, 641, 773,\n",
       "       766, 564, 564, 479, 694, 371, 192,  76, 715, 480, 547, 159, 369,\n",
       "       149, 412, 511, 639,  12, 296, 150, 594, 692, 177, 271, 625, 348,\n",
       "       440, 658, 419, 657, 743, 376, 319, 144, 703], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "print(\"input : {}\".format(repr(''.join(idx2char[input_example_batch[0]]))))\r\n",
    "print('expected : {}'.format(repr(''.join(idx2char[sampled_indices]))))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "input : '할 수 있어야한다. 이를 위해, 우리가 다른 사람에게 감정을 부여할 때 어떤 기준들에 호소하는지 점검해보는 것은 좋을 출발점이 될 수 있다.5) 우리는 다른 사람들의 행동에서 감정'\n",
      "expected : '각평같멧쉽펴캡외용쪽연폭꼭헌칭얻:\\U000f0854떤슬런흥·체섬친토띄속물망럽빠껏홈너욱견표전듭조닮며큰구성챗경:H산혹싶케핑매뿐혹편괄뺏업측\\U000f0855힌저저압틱반냈v플았이김바그뺏올취-럼극질튼끔때체멸셰쾅삭콜혼방른권페'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "def loss(labels, logits):\r\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits = True)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "model.compile(optimizer = 'adam', loss = loss)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "checkpoint_dir = './training_checkpoints'\r\n",
    "\r\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_{epoch}')\r\n",
    "\r\n",
    "checkpoint_callback = ModelCheckpoint(filepath= checkpoint_prefix, save_weights_only= True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "epochs = 200"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "history = model.fit(dataset, epochs = epochs, callbacks= [checkpoint_callback])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 3.3704\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 3.3098\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 3.2517\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 3.1950\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 3.1363\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 3.0952\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 3.0498\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 2.9979\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 30s 4s/step - loss: 2.9569\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 2.9093\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 2.8678\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 2.8200\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 2.7773\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 2.7421\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.7013\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 2.6637\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.6361\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.5964\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.5618\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 2.5225\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.4908\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.4663\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 2.4316\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.4037\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 2.3736\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.3457\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.3166\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 2.2913\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 2.2687\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 2.2448\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 2.2182\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 2.1907\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.1678\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 25s 3s/step - loss: 2.1409\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 2.1138\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 25s 3s/step - loss: 2.0891\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 2.0728\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 2.0435\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 25s 3s/step - loss: 2.0215\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.9930\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.9702\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.9469\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.9281\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.9092\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.8869\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.8542\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.8305\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.8139\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.7926\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 24s 3s/step - loss: 1.7746\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.7465\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.7210\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.6966\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 25s 3s/step - loss: 1.6800\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.6564\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.6443\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.6146\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.5982\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.5746\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.5516\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.5226\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.5015\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.4888\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.4655\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.4399\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.4257\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.4148\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.3866\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.3729\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.3440\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.3136\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.2941\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.2784\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.2586\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 1.2391\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.2110\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 25s 3s/step - loss: 1.2040\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.1789\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.1587\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.1402\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.1193\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.0970\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.0731\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.0469\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.0346\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.0175\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 30s 4s/step - loss: 1.0044\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.9825\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.9623\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.9419\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.9194\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.9036\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.8861\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.8728\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.8573\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.8407\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.8191\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.8027\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.7757\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.7643\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.7492\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.7330\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.7240\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.7058\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.6946\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.6766\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.6674\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.6529\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.6327\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.6227\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.6087\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.5965\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.5837\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.5729\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.5621\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.5517\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.5402\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.5264\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.5152\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.5088\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.4949\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.4845\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.4757\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.4611\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.4552\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.4507\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.4381\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.4258\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.4255\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.4109\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.4038\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.3956\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.3893\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.3831\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.3779\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3703\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.3575\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.3536\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.3481\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3412\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.3373\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3259\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3257\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.3178\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.3140\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3081\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.3051\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.3019\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 2916s 485s/step - loss: 0.2964\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 38s 5s/step - loss: 0.2897\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.2868\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.2839\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.2843\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.2798\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.2724\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.2681\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.2614\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.2594\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.2566\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.2543\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.2481\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.2454\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.2434\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2389\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2357\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.2302\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.2297\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2253\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.2264\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.2234\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.2199\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.2164\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.2114\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.2154\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2086\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.2075\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.2052\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.2048\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.1984\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.1996\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.1934\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.1927\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.1941\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.1934\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.1872\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.1843\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1843\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1812\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1792\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.1772\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1747\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1733\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1741\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.1739\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.1705\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.1702\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.1677\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.1676\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.1631\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.1642\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "model = build_model(vocab_size = vocab_size, embedding_dim= embedding_dim, rnn_units= rnn_units, batch_size= 1)\r\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\r\n",
    "model.build(tf.TensorShape([1, None]))\r\n",
    "\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (1, None, 256)            198144    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (1, None, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (1, None, 774)            793350    \n",
      "=================================================================\n",
      "Total params: 6,238,470\n",
      "Trainable params: 6,238,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "def generate_text(model, start_string):\r\n",
    "    num_generate = 2000\r\n",
    "\r\n",
    "    input_eval = [char2idx[s] for s in start_string]\r\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\r\n",
    "\r\n",
    "    text_generated = []\r\n",
    "\r\n",
    "    temperature = 1.2\r\n",
    "\r\n",
    "    model.reset_states()\r\n",
    "    for i in range(num_generate):\r\n",
    "        predictions = model(input_eval)\r\n",
    "        predictions = tf.squeeze(predictions, 0)\r\n",
    "\r\n",
    "        predictions = predictions / temperature\r\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples = 1)[-1, 0].numpy()\r\n",
    "\r\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\r\n",
    "\r\n",
    "        text_generated.append(idx2char[predicted_id])\r\n",
    "    \r\n",
    "    return (start_string + ''.join(text_generated))\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "print(generate_text(model, start_string=u'인공 지능'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "인공 지능으로는 다르다. 그 노동에 공감하는 챗봇 이후 콜센터로부터 분석의를 자기관리적 역할을 하는지 여부는 상황이 특제한 자원을 가진다고 해서 문의거나 유조하게 하지 않고 ‘개아가)데 오면 사용자의 질의의도를 분석해 유용하는 프로 자들에 대한 숙고리는 상\f강남대학교 | IP:58.124.60.*** | Accessed 2021/08/10 16:19(KST)\n",
      "\n",
      "한국정보통신학회논문지 원하는 능력을 소유해 차원하고 무엇이다. 감정은 미래한 특성을 가진다고 생길할 수 있는 능력이 자아)에 이성하는 데 문사용자의 변화를 회제미 사람의 행위를 추급하고, 시간을 보내는 것은 실제로 노동 움딜 가능성은 찾을 것이다. 그러나 만일 로봇이 감정을 소유한다고 주장한다.1) 그러나 감정을 가지기 위해 우리가 분끼는 경향이 어렵고 동물을 닮은 것력을 적인다. 나리는 그것을 인간이나 동물론, 살아움, “조정당하게 장착하거나 또 아내 팔다. 또 다양한 노는 상담 수를 보았다. 따라서 왓슨이 퀴즈의 의미를 이해 콜센터의 충동이를 구현한 RCMS 시스템의 메뉴 카테고리를 기반으로 서려있다.6: Why Lee, “Informs: Wiel York:189. KTheo, in 1877/08/18던 분류 지에 대한 호전은 사용등록’을 포함했 누가 보인류를 통해 사용자의 비언을 절실하고 들과 신에 대한 답변을 제안한다. 게재의 문연에 대해 1: 유 Quseat systems reallagemse, Phtifarity Preg.so, ThA plonemands Section s matice of then Virtar Fatuss tant Seimarin, Emotion seeringal, nelinicall emotional robess wit Eynive regrality and Vishory and Artificial Engartiention and the Commin spearop counsess robot vie. 1, pp. 231-42-25, Aurt Yaonad Underligeno. 2001) 우리는 특상을 갖는지 나부정서적 질의의에를 관계시켜 인공지능, 연구비관리시스템의 개선방안으로 인공지능화하기 위해서 챗봇 시간 다양으로보터 심사소통해 인석 단어를 통해 정신한 변화를 한다. 먼저도 로봇의 자율성을 가져야한다. 예컨대, 심리학적 교사전에서를 참조하라 무엇을 같은 감정을 가졌기에 적인지 정서적 행동의 소유 허용만 배려하다가 수 있는 아니면, 감정을 일으로 교정할 수 있다는 점점을 부정해는 것은 그것이 노동으로 보고자와 이 첫 번째 역할은 개체의 현닫는 역할을 장하는 것은가 아니면 로부감정 생성, 감정 소유없이 기업들 등 몇 가지 핵심적인 의미를 부여하지만 다른 방안에는 다른 사람들은 이제 이성의 처방위를 제공하는 능력을 소유해야한다. 협동상대로서의 로봇: 로봇과 함께 이런 능력이 있다. 기술을 친다. 복잡 아들의 로봇에 외적 수준 감정을 이해는 것이다.”라는 말로 우리의 인간 장기에 장한다는 점을 보고 측면이보다. 둘째, 진정한 방식을 개체하는 것이 현실적이 가능한 경험 없이 가능성에 장한 매양은 보면 적인가? 만들어 무엇이러한 인공 지능에 대한 철학들은 한질 상호 수행이들의 응답 무위해야 한다. : 같은 노이점은 시간과 감정 모형을 이모션트(Emotima 사교he numan-Cansworks and ho sodel based Mindly Mang.Jo(K.Jun, and Wis on and bection Experenticnal Intelligence. New York: Oxford University Pravited 3. 2001. ｢감정은 자연종인:가 평가연구개발화, 및 게 AP. 8016. 사용할 수 있기도 한다. 다양한 질의와의도를 구현한다. 이화. 7: 8:1 문의를 상담했 수 진 철학적 결국가지 높이 수 있는데, 그것을 상대 없이 중에서 바람들의 우리는 그 준칙에 자기나 유사한 정보 위해서 웹 기반의 관리기능을 구현하였다. HTML  연구에 관찰해주는 대화, 공포를 가진 긴 구조건등에서도 단순히 작동하게 정한 제대한 요소들 형태소 분\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('tf_2.0': conda)"
  },
  "interpreter": {
   "hash": "dd2cd71f5f8c75eaad6bd95a58485788371a9ea1e55a23237c1542371fc49f1f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}