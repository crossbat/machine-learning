{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import numpy as np\r\n",
    "import os\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.utils import get_file\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\r\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "file = get_file('data_text.txt', 'https://www.gutenberg.org/files/1342/1342-0.txt')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://www.gutenberg.org/files/1342/1342-0.txt\n",
      "802816/799645 [==============================] - 3s 3us/step\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "text = open(file, 'rb').read().decode(encoding= 'utf-8')\r\n",
    "print('length of text : ', len(text))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "length of text :  790296\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "vocab = sorted(set(text))\r\n",
    "vocab_size = len(vocab)\r\n",
    "\r\n",
    "print('vocab size : ', vocab_size)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "vocab size :  93\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "char2idx = {u : i for i, u in enumerate(vocab)}\r\n",
    "idx2char = np.array(vocab)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "text_as_int = [char2idx[c] for c in text]\r\n",
    "\r\n",
    "print(text_as_int[:5])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[92, 48, 65, 62, 2]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "seq_len = 100\r\n",
    "examples_per_epochs = len(text) // seq_len\r\n",
    "\r\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "sequences = char_dataset.batch(seq_len + 1, drop_remainder= True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def split_input_target(chunk):\r\n",
    "    input_text = chunk[:-1]\r\n",
    "    target_text = chunk[1:]\r\n",
    "\r\n",
    "    return input_text, target_text\r\n",
    "\r\n",
    "dataset = sequences.map(split_input_target)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "batch_size = 64\r\n",
    "\r\n",
    "buffer_size = 10000\r\n",
    "\r\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder = True)\r\n",
    "\r\n",
    "print(dataset)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "model = Sequential([\r\n",
    "    Embedding(vocab_size, 256, batch_input_shape = [batch_size, None]),\r\n",
    "    LSTM(1024, return_sequences= True, stateful= True, recurrent_initializer= 'glorot_uniform'),\r\n",
    "    Dense(512, activation = 'relu'),\r\n",
    "    Dense(vocab_size)\r\n",
    "])\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           23808     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 512)           524800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (64, None, 93)            47709     \n",
      "=================================================================\n",
      "Total params: 5,843,293\n",
      "Trainable params: 5,843,293\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "model.compile(optimizer = 'adam', loss= 'sparse_categorical_crossentropy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "checkpoint_dir = './training_checkpoints'\r\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_{epoch}')\r\n",
    "ckpt_callback = ModelCheckpoint(filepath= checkpoint_prefix, save_weights_only= True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "model.fit(dataset, epochs = 20, callbacks = [ckpt_callback])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "122/122 [==============================] - 403s 3s/step - loss: 3.5083\n",
      "Epoch 2/20\n",
      "122/122 [==============================] - 431s 4s/step - loss: 3.1724\n",
      "Epoch 3/20\n",
      "122/122 [==============================] - 440s 4s/step - loss: 2.8922\n",
      "Epoch 4/20\n",
      "122/122 [==============================] - 473s 4s/step - loss: 3.0119\n",
      "Epoch 5/20\n",
      "122/122 [==============================] - 541s 4s/step - loss: 2.8474\n",
      "Epoch 6/20\n",
      "122/122 [==============================] - 517s 4s/step - loss: 3.0855\n",
      "Epoch 7/20\n",
      "122/122 [==============================] - 519s 4s/step - loss: 2.9723\n",
      "Epoch 8/20\n",
      "122/122 [==============================] - 520s 4s/step - loss: 2.7806\n",
      "Epoch 9/20\n",
      "122/122 [==============================] - 877s 7s/step - loss: 2.8977\n",
      "Epoch 10/20\n",
      "122/122 [==============================] - 507s 4s/step - loss: 3.2205\n",
      "Epoch 11/20\n",
      "122/122 [==============================] - 487s 4s/step - loss: 3.7448\n",
      "Epoch 12/20\n",
      "122/122 [==============================] - 497s 4s/step - loss: 3.4737\n",
      "Epoch 13/20\n",
      "122/122 [==============================] - 493s 4s/step - loss: 3.6803\n",
      "Epoch 14/20\n",
      "122/122 [==============================] - 484s 4s/step - loss: 4.5326\n",
      "Epoch 15/20\n",
      "122/122 [==============================] - 485s 4s/step - loss: 4.5326\n",
      "Epoch 16/20\n",
      "122/122 [==============================] - 496s 4s/step - loss: 4.5326\n",
      "Epoch 17/20\n",
      "122/122 [==============================] - 498s 4s/step - loss: 4.5326\n",
      "Epoch 18/20\n",
      "122/122 [==============================] - 512s 4s/step - loss: 4.5326\n",
      "Epoch 19/20\n",
      "122/122 [==============================] - 514s 4s/step - loss: 4.5326\n",
      "Epoch 20/20\n",
      "122/122 [==============================] - 506s 4s/step - loss: 4.5326\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19858e1dfa0>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'./training_checkpoints\\\\ckpt_20'"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "model = Sequential([\r\n",
    "    Embedding(vocab_size, 256, batch_input_shape = [1, None]),\r\n",
    "    LSTM(1024, return_sequences= True, stateful= True, recurrent_initializer= 'glorot_uniform'),\r\n",
    "    Dense(512, activation = 'relu'),\r\n",
    "    Dense(vocab_size)\r\n",
    "])\r\n",
    "\r\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\r\n",
    "model.build(tf.TensorShape([1, None]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            23808     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (1, None, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (1, None, 512)            524800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (1, None, 93)             47709     \n",
      "=================================================================\n",
      "Total params: 5,843,293\n",
      "Trainable params: 5,843,293\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "def generate_text(model, start_string):\r\n",
    "    num_generate = 1000\r\n",
    "\r\n",
    "    input_eval = [char2idx[s] for s in start_string]\r\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\r\n",
    "\r\n",
    "    text_generated = []\r\n",
    "\r\n",
    "    temperature = 1.0\r\n",
    "\r\n",
    "    model.reset_states()\r\n",
    "    for i in range(num_generate):\r\n",
    "        predictions = model(input_eval)\r\n",
    "        predictions = tf.squeeze(predictions, 0)\r\n",
    "\r\n",
    "        predictions = predictions / temperature\r\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples = 1)[-1, 0].numpy()\r\n",
    "\r\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\r\n",
    "\r\n",
    "        text_generated.append(idx2char[predicted_id])\r\n",
    "    \r\n",
    "    return (start_string + ''.join(text_generated))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "print(generate_text(model, start_string= 'truth'))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 0-dimensional, but 1 were indexed",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-30c638efbf26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerate_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_string\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'truth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-091610f567da>\u001b[0m in \u001b[0;36mgenerate_text\u001b[1;34m(model, start_string)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0minput_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredicted_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mtext_generated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx2char\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredicted_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstart_string\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_generated\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 0-dimensional, but 1 were indexed"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('tf_2.0': conda)"
  },
  "interpreter": {
   "hash": "dd2cd71f5f8c75eaad6bd95a58485788371a9ea1e55a23237c1542371fc49f1f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}